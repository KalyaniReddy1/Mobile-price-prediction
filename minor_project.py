# -*- coding: utf-8 -*-
"""minor project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XIKSQadzblbjgBLk3OIyGkLi3c_yjyg1
"""

import numpy as np
import matplotlib.pyplot as pt
import pandas as pd
import seaborn as sns

df = pd.read_csv('/mobile_price_range_data (1).csv')
df.head()

df.shape

df.isnull().sum()

df.dtypes

from sklearn.model_selection import train_test_split

x = df.iloc[:,:-1]
y = df.iloc[:,-1]
print(x.shape)
print(y.shape)

x.head()

y.head()

x_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size=0.025)
x_te.head()

print(x_tr.shape)
print(x_te.shape)
print(y_tr.shape)
print(y_te.shape)

"""**Logistic** **Regression**"""

from sklearn.linear_model import LogisticRegression
m1 = LogisticRegression()

m1.fit(x_tr,y_tr)

print('training score',m1.score(x_tr,y_tr))
print('testing score',m1.score(x_te,y_te))

ypred = m1.predict(x_te)
ypred

x_te['y_actual'] = y_te
x_te['ypred'] = ypred
x_te.head()

from sklearn.metrics import confusion_matrix,classification_report

cm = confusion_matrix(y_te,ypred)
cm

cr = classification_report(y_te,ypred)
print(cr)

"""**KNN** **Classification**"""

x_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size=0.025)
x_te.head()

from sklearn.neighbors import KNeighborsClassifier

m2 = KNeighborsClassifier(n_neighbors=43)
m2.fit(x_tr,y_tr)

print('training_score1',m2.score(x_tr,y_tr))
print('test_score1',m2.score(x_te,y_te))

ypred1 = m2.predict(x_te)
print(ypred1)

cm1 = confusion_matrix(y_te,ypred1)
print(cm1)

cr1 = classification_report(y_te,ypred1)
print(cr1)

sns.scatterplot(df['battery_power'],df['ram'],hue=df['price_range'],palette = 'rainbow')

"""**Build** **the** **SVM** **model**"""

from sklearn.svm import SVC

x_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size=0.1)
x_tr

m3 = SVC(kernel = 'linear',C=1)
m3.fit(x_tr,y_tr)

print('training score',m3.score(x_tr,y_tr))
print('test score',m3.score(x_te,y_te))

ypred2 = m3.predict(x_te)
ypred2

from sklearn.metrics import confusion_matrix, classification_report

cm2 = confusion_matrix(y_te,ypred2)
cr2 = classification_report(y_te,ypred2)
print(cm2)
print(cr2)

"""**RBF** **Kernel**"""

m4 = SVC(kernel = 'rbf',gamma=0.00001,C=10)
m4.fit(x_tr,y_tr)

print('training score',m4.score(x_tr,y_tr))
print('test score',m4.score(x_te,y_te))

ypred3 = m4.predict(x_te)
print(ypred3)

cm3 = confusion_matrix(y_te,ypred3)
cr3 = classification_report(y_te,ypred3)
print(cm3)
print(cr3)

"""**Poly**"""

m5 = SVC(kernel = 'poly',C=10)
m5.fit(x_tr,y_tr)

print('training score',m5.score(x_tr,y_tr))
print('test score',m5.score(x_te,y_te))

ypred4 = m5.predict(x_te)
print(ypred4)

cm4 = confusion_matrix(y_te,ypred4)
cr4 = classification_report(y_te,ypred4)
print(cm4)
print(cr4)

from sklearn.metrics import accuracy_score

## m1.accuracy_score = 0.66
## m2.accuracy_score = 0.94
## m3.accuracy_score = 0.96
## m4.accuracy_score = 0.92
## m5.accuracy_score = 0.94

"""Hence, SVM classification with linear kernel has more accuracy score. This model can be used to predict price range """

